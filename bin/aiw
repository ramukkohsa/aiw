#!/usr/bin/env bash
# aiw — Unified AI Workspace CLI
# Manages shared context, skills, sessions, and tool switching.
# Install: ln -sf ~/.ai-workspace/bin/aiw ~/.local/bin/aiw

set -euo pipefail

VERSION="1.0.0"
WORKSPACE="${HOME}/.ai-workspace"
CONFIG="${WORKSPACE}/config.toml"
ADAPTERS="${WORKSPACE}/adapters"
SESSIONS="${WORKSPACE}/sessions"

# ── Colors ──
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
BOLD='\033[1m'
DIM='\033[2m'
NC='\033[0m'

# ── Helpers ──

info()  { echo -e "${BLUE}[aiw]${NC} $*"; }
ok()    { echo -e "${GREEN}[aiw]${NC} $*"; }
warn()  { echo -e "${YELLOW}[aiw]${NC} $*"; }
err()   { echo -e "${RED}[aiw]${NC} $*" >&2; }

check_workspace() {
    if [ ! -d "$WORKSPACE" ]; then
        err "Workspace not found at ${WORKSPACE}"
        err "Run the setup script first."
        exit 1
    fi
    if [ ! -f "$CONFIG" ]; then
        err "Config not found at ${CONFIG}"
        exit 1
    fi
}

# Get config value: config_get "workspace" "default_tool"
config_get() {
    local section="$1"
    local key="$2"
    sed -n "/^\[${section}\]/,/^\[/p" "$CONFIG" | grep "^${key}" | head -1 | sed 's/.*= *"//' | sed 's/".*//'
}

# Get model ID for a KiloCode role (arch/code/quick/review)
config_get_model() {
    local role="$1"
    config_get "tools.kilocode.models" "$role"
}

# Get variant (reasoning effort) for a KiloCode role
config_get_variant() {
    local role="$1"
    config_get "tools.kilocode.variants" "$role"
}

# Get project path from config
project_path() {
    local project="$1"
    grep -A5 "\\[projects\\.${project}\\]" "$CONFIG" | grep "^path" | head -1 | sed 's/.*= *"//' | sed 's/".*//'
}

# List all project names
list_projects() {
    grep '^\[projects\.' "$CONFIG" | sed 's/\[projects\.\(.*\)\]/\1/'
}

# Get default project
default_project() {
    config_get "defaults" "default_project"
}

# Get default tool
default_tool() {
    config_get "defaults" "default_tool"
}

# ── Auto-Detection ──

# Detect best KiloCode role for a project using heuristic signal scoring.
# Outputs role name (arch/code/quick/review) to stdout, signal details to stderr.
auto_detect_role() {
    local project="${1:?Usage: auto_detect_role <project>}"
    local path
    path=$(project_path "$project")

    if [ -z "$path" ] || [ ! -d "$path" ]; then
        err "Project path not found for ${project}"
        echo "code"
        return
    fi

    # Check config overrides first
    local override
    override=$(config_get "auto_detect.overrides" "$project")
    if [ -n "$override" ]; then
        echo -e "  ${DIM}override: ${project} = ${override}${NC}" >&2
        echo "$override"
        return
    fi

    local enabled
    enabled=$(config_get "auto_detect" "enabled")
    if [ "$enabled" = "false" ]; then
        local default_role
        default_role=$(config_get "auto_detect" "default_role")
        echo -e "  ${DIM}auto_detect disabled, using default: ${default_role:-code}${NC}" >&2
        echo "${default_role:-code}"
        return
    fi

    # Score accumulators
    local score_arch=0 score_code=5 score_quick=0 score_review=0
    local signals=""

    # ── Tier 1: Git state ──
    if git -C "$path" rev-parse --is-inside-work-tree &>/dev/null; then
        # Branch name keywords
        local branch
        branch=$(git -C "$path" symbolic-ref --short HEAD 2>/dev/null || echo "")
        if [ -n "$branch" ]; then
            case "$branch" in
                *fix*|*typo*|*hotfix*|*patch*)
                    score_quick=$((score_quick + 30))
                    signals="${signals}\n        branch: \"${branch}\" → quick (+30)" ;;
                *feat*|*add*|*impl*|*build*)
                    score_code=$((score_code + 20))
                    signals="${signals}\n        branch: \"${branch}\" → code (+20)" ;;
                *rfc*|*design*|*arch*|*plan*)
                    score_arch=$((score_arch + 30))
                    signals="${signals}\n        branch: \"${branch}\" → arch (+30)" ;;
                *review*|*audit*|*test*)
                    score_review=$((score_review + 30))
                    signals="${signals}\n        branch: \"${branch}\" → review (+30)" ;;
            esac
        fi

        # Diff stat: count changed files and lines
        local diff_files diff_lines
        diff_files=$(git -C "$path" diff --stat HEAD 2>/dev/null | tail -1 | grep -oP '\d+ file' | grep -oP '\d+' || echo "0")
        diff_lines=$(git -C "$path" diff --stat HEAD 2>/dev/null | tail -1 | grep -oP '\d+ insertion' | grep -oP '\d+' || echo "0")
        if [ "$diff_files" = "0" ] && [ -z "$(git -C "$path" diff --name-only HEAD 2>/dev/null)" ]; then
            score_arch=$((score_arch + 10))
            signals="${signals}\n        diff: 0 files changed → arch (+10)"
        elif [ "$diff_files" -le 3 ] 2>/dev/null && [ "$diff_lines" -lt 50 ] 2>/dev/null; then
            score_quick=$((score_quick + 15))
            signals="${signals}\n        diff: ${diff_files} files, ${diff_lines} lines → quick (+15)"
        else
            score_code=$((score_code + 10))
            signals="${signals}\n        diff: ${diff_files} files → code (+10)"
        fi

        # Recent commits (24h) — keyword scan
        local recent_msgs
        recent_msgs=$(git -C "$path" log --since="24 hours ago" --pretty=format:"%s" 2>/dev/null | head -10)
        if [ -n "$recent_msgs" ]; then
            if echo "$recent_msgs" | grep -qiE 'fix|typo|hotfix|patch'; then
                score_quick=$((score_quick + 10))
                signals="${signals}\n        commits: fix/typo keywords → quick (+10)"
            elif echo "$recent_msgs" | grep -qiE 'feat|add|implement|build'; then
                score_code=$((score_code + 10))
                signals="${signals}\n        commits: feat/build keywords → code (+10)"
            elif echo "$recent_msgs" | grep -qiE 'refactor|design|architect|rfc'; then
                score_arch=$((score_arch + 10))
                signals="${signals}\n        commits: design/refactor keywords → arch (+10)"
            elif echo "$recent_msgs" | grep -qiE 'review|test|validate|audit'; then
                score_review=$((score_review + 10))
                signals="${signals}\n        commits: review/test keywords → review (+10)"
            fi
        fi

        # Uncommitted file types
        local changed_files
        changed_files=$(git -C "$path" diff --name-only 2>/dev/null; git -C "$path" diff --cached --name-only 2>/dev/null)
        if [ -n "$changed_files" ]; then
            local has_code=false has_test=false has_md_only=true
            while IFS= read -r f; do
                case "$f" in
                    *.md) ;;
                    *test*|*spec*) has_test=true; has_md_only=false ;;
                    *) has_code=true; has_md_only=false ;;
                esac
            done <<< "$changed_files"
            if [ "$has_md_only" = true ]; then
                score_quick=$((score_quick + 10))
                signals="${signals}\n        files: only .md → quick (+10)"
            elif [ "$has_test" = true ]; then
                score_review=$((score_review + 10))
                signals="${signals}\n        files: test files → review (+10)"
            elif [ "$has_code" = true ]; then
                score_code=$((score_code + 10))
                signals="${signals}\n        files: code files → code (+10)"
            fi
        fi
    else
        signals="${signals}\n        git: not a repo (skipped)"
    fi

    # ── Tier 2: Brief content ──
    local proj_brief="${WORKSPACE}/context/projects/${project}/brief.md"
    if [ -f "$proj_brief" ]; then
        local brief_head
        brief_head=$(head -c 500 "$proj_brief")
        if echo "$brief_head" | grep -qiE 'architect|design|rfc|complex|multi.?agent'; then
            score_arch=$((score_arch + 15))
            signals="${signals}\n        brief: architecture/design keywords → arch (+15)"
        fi
        if echo "$brief_head" | grep -qiE 'implement|build|feature|develop|migration'; then
            score_code=$((score_code + 10))
            signals="${signals}\n        brief: implement/build keywords → code (+10)"
        fi
        if echo "$brief_head" | grep -qiE 'fix|typo|tweak|minor|simple'; then
            score_quick=$((score_quick + 10))
            signals="${signals}\n        brief: fix/typo keywords → quick (+10)"
        fi
        if echo "$brief_head" | grep -qiE 'review|validate|audit|test|coverage'; then
            score_review=$((score_review + 10))
            signals="${signals}\n        brief: review/validate keywords → review (+10)"
        fi
        if echo "$brief_head" | grep -qiE 'production|stability|maintain|operational'; then
            score_code=$((score_code + 5))
            signals="${signals}\n        brief: production/stability → code (+5)"
        fi
    fi

    # Stuck.md active blockers → arch
    local stuck="${WORKSPACE}/context/stuck.md"
    if [ -f "$stuck" ] && ! grep -q "^_No active blockers" "$stuck" && grep -q "^## STUCK-" "$stuck"; then
        score_arch=$((score_arch + 5))
        signals="${signals}\n        stuck: active blockers → arch (+5)"
    fi

    # ── Tier 3: Project config ──
    local tags
    tags=$(grep -A10 "\\[projects\\.${project}\\]" "$CONFIG" | grep "^tags" | head -1 | sed 's/tags *= *//')
    if [ -n "$tags" ]; then
        if echo "$tags" | grep -qiE 'production'; then
            score_code=$((score_code + 5))
            signals="${signals}\n        tags: production → code (+5)"
        fi
        if echo "$tags" | grep -qiE 'agents|architecture'; then
            score_arch=$((score_arch + 5))
            signals="${signals}\n        tags: agents/architecture → arch (+5)"
        fi
        if echo "$tags" | grep -qiE 'monitoring'; then
            score_review=$((score_review + 3))
            signals="${signals}\n        tags: monitoring → review (+3)"
        fi
    fi

    # File structure hints
    if [ -d "${path}/src" ]; then
        local has_tests=false
        if find "$path" -maxdepth 3 -name "*test*" -o -name "*spec*" 2>/dev/null | head -1 | grep -q .; then
            has_tests=true
        fi
        if [ "$has_tests" = true ]; then
            score_code=$((score_code + 3))
            signals="${signals}\n        structure: src/ + tests → code (+3)"
        fi
    fi

    # ── Tier 4: Session history ──
    local today
    today=$(date +%Y-%m-%d)
    local session_dir="${WORKSPACE}/history/sessions/${today}"
    if [ -d "$session_dir" ]; then
        local last_kilo_session=""
        last_kilo_session=$(find "$session_dir" -name "kilo-*_*.json" -o -name "kilo_*.json" 2>/dev/null | sort | tail -1)
        if [ -n "$last_kilo_session" ]; then
            local sess_tool sess_project sess_started
            sess_tool=$(python3 -c "import json; print(json.load(open('${last_kilo_session}'))['tool'])" 2>/dev/null || echo "")
            sess_project=$(python3 -c "import json; print(json.load(open('${last_kilo_session}'))['project'])" 2>/dev/null || echo "")
            sess_started=$(python3 -c "import json; print(json.load(open('${last_kilo_session}')).get('started',''))" 2>/dev/null || echo "")

            if [ "$sess_project" = "$project" ] && [ -n "$sess_tool" ] && [ -n "$sess_started" ]; then
                # Check if within 4 hours
                local sess_epoch now_epoch
                sess_epoch=$(date -d "$sess_started" +%s 2>/dev/null || echo "0")
                now_epoch=$(date +%s)
                local diff_secs=$(( now_epoch - sess_epoch ))

                if [ "$diff_secs" -lt 14400 ] && [ "$diff_secs" -ge 0 ]; then
                    local sess_role="${sess_tool#kilo-}"
                    case "$sess_role" in
                        arch)   score_arch=$((score_arch + 8));     signals="${signals}\n        session: ${sess_tool} ${diff_secs}s ago → arch (+8)" ;;
                        code)   score_code=$((score_code + 8));     signals="${signals}\n        session: ${sess_tool} ${diff_secs}s ago → code (+8)" ;;
                        quick)  score_quick=$((score_quick + 5));   signals="${signals}\n        session: ${sess_tool} ${diff_secs}s ago → quick (+5)" ;;
                        review) score_review=$((score_review + 8)); signals="${signals}\n        session: ${sess_tool} ${diff_secs}s ago → review (+8)" ;;
                    esac
                fi
            fi
        fi
    fi

    # ── Determine winner ──
    # Tie-breaking priority: code > arch > review > quick
    local best_role="code"
    local best_score=$score_code

    if [ $score_arch -gt $best_score ]; then
        best_role="arch"; best_score=$score_arch
    fi
    # arch beats code on tie (code already set as default)
    if [ $score_arch -eq $best_score ] && [ "$best_role" = "code" ] && [ $score_arch -gt $score_code ]; then
        best_role="arch"; best_score=$score_arch
    fi
    if [ $score_review -gt $best_score ]; then
        best_role="review"; best_score=$score_review
    fi
    if [ $score_quick -gt $best_score ]; then
        best_role="quick"; best_score=$score_quick
    fi

    # Confidence level
    local scores=($score_arch $score_code $score_quick $score_review)
    local second_best=0
    for s in "${scores[@]}"; do
        if [ "$s" != "$best_score" ] && [ "$s" -gt "$second_best" ]; then
            second_best=$s
        fi
    done
    local margin=$((best_score - second_best))
    local confidence="guess"
    if [ $margin -ge 20 ]; then confidence="high"
    elif [ $margin -ge 10 ]; then confidence="medium"
    elif [ $margin -ge 5 ]; then confidence="low"
    fi

    # Output signals to stderr
    local show_signals
    show_signals=$(config_get "auto_detect" "show_signals")
    if [ "$show_signals" != "false" ]; then
        echo -e "${BLUE}[aiw]${NC} Auto-detecting role for ${BOLD}${project}${NC}..." >&2
        echo -e "${BLUE}[aiw]${NC} Signals:${signals}" >&2
        echo -e "${BLUE}[aiw]${NC} Scores: arch=${score_arch}  code=${score_code}  quick=${score_quick}  review=${score_review}" >&2
        echo -e "${BLUE}[aiw]${NC} → ${GREEN}kilo-${best_role}${NC} (confidence: ${confidence})" >&2
    fi

    # Return role name to stdout
    echo "$best_role"
}

# ── Cross-Tool Auto-Detection ──

# Detect best tool (claude, kilo-arch, kilo-code, kilo-quick, kilo-review, cline, codex, ralph)
# for a project, combining project signals with optional task description.
# Outputs full tool name to stdout, signal details to stderr.
auto_detect_tool() {
    local project="${1:?Usage: auto_detect_tool <project>}"
    local task_desc="${2:-}"

    local path
    path=$(project_path "$project")

    if [ -z "$path" ] || [ ! -d "$path" ]; then
        err "Project path not found for ${project}"
        echo "kilo-code"
        return
    fi

    # Check if cross-tool routing is enabled
    local routing_enabled
    routing_enabled=$(config_get "auto_detect.tool_routing" "enabled")
    if [ "$routing_enabled" = "false" ]; then
        # Fall back to KiloCode-only detection
        local role
        role=$(auto_detect_role "$project")
        echo "kilo-${role}"
        return
    fi

    local cross_tool_margin claude_upgrade_margin
    cross_tool_margin=$(config_get "auto_detect.tool_routing" "cross_tool_margin")
    claude_upgrade_margin=$(config_get "auto_detect.tool_routing" "claude_upgrade_margin")
    cross_tool_margin="${cross_tool_margin:-25}"
    claude_upgrade_margin="${claude_upgrade_margin:-30}"

    # ── Phase 1: Project signal scoring ──
    # Get KiloCode role scores by capturing auto_detect_role signals
    local role_output
    role_output=$(auto_detect_role "$project" 2>&1)
    local detected_role
    detected_role=$(auto_detect_role "$project" 2>/dev/null)

    # Parse role scores from stderr output
    local raw_kilo_arch=0 raw_kilo_code=0 raw_kilo_quick=0 raw_kilo_review=0
    local scores_line
    scores_line=$(echo "$role_output" | grep "Scores:" | head -1)
    if [ -n "$scores_line" ]; then
        raw_kilo_arch=$(echo "$scores_line" | grep -oP 'arch=\K\d+' || echo "0")
        raw_kilo_code=$(echo "$scores_line" | grep -oP 'code=\K\d+' || echo "0")
        raw_kilo_quick=$(echo "$scores_line" | grep -oP 'quick=\K\d+' || echo "0")
        raw_kilo_review=$(echo "$scores_line" | grep -oP 'review=\K\d+' || echo "0")
    fi

    # When user provides a task description, scale project signals down to
    # tiebreaker weight (÷3) so the task description is the dominant signal.
    # Without a task description, project signals are used at full strength.
    local score_kilo_arch score_kilo_code score_kilo_quick score_kilo_review
    if [ -n "$task_desc" ]; then
        score_kilo_arch=$((raw_kilo_arch / 3))
        score_kilo_code=$((raw_kilo_code / 3))
        score_kilo_quick=$((raw_kilo_quick / 3))
        score_kilo_review=$((raw_kilo_review / 3))
    else
        score_kilo_arch=$raw_kilo_arch
        score_kilo_code=$raw_kilo_code
        score_kilo_quick=$raw_kilo_quick
        score_kilo_review=$raw_kilo_review
    fi

    # Non-KiloCode tool scores
    local score_claude=0 score_cline=0 score_codex=0 score_ralph=0
    local tool_signals=""

    # Project signal weight: full when no task desc, reduced when task desc provided
    local proj_weight=1
    if [ -n "$task_desc" ]; then
        proj_weight=0  # Skip project signals for non-kilo tools when user described their task
    fi

    # Cline signals: .vscode dir, CSS/TSX files
    if [ "$proj_weight" -eq 1 ] && [ -d "${path}/.vscode" ]; then
        score_cline=$((score_cline + 15))
        tool_signals="${tool_signals}\n        .vscode/ exists → cline (+15)"
    fi
    if [ "$proj_weight" -eq 1 ] && git -C "$path" rev-parse --is-inside-work-tree &>/dev/null; then
        local changed_exts
        changed_exts=$(git -C "$path" diff --name-only 2>/dev/null; git -C "$path" diff --cached --name-only 2>/dev/null)
        if echo "$changed_exts" | grep -qiE '\.(css|scss|tsx|jsx)$'; then
            score_cline=$((score_cline + 15))
            tool_signals="${tool_signals}\n        css/tsx files changed → cline (+15)"
        fi
    fi

    # Cline: project tags contain "ui" or "frontend"
    if [ "$proj_weight" -eq 1 ]; then
        local tags
        tags=$(grep -A10 "\\[projects\\.${project}\\]" "$CONFIG" | grep "^tags" | head -1 | sed 's/tags *= *//')
        if [ -n "$tags" ]; then
            if echo "$tags" | grep -qiE '"ui"|"frontend"'; then
                score_cline=$((score_cline + 10))
                tool_signals="${tool_signals}\n        tags: ui/frontend → cline (+10)"
            fi
        fi
    fi

    # Codex: no git repo, script-like directory
    if [ "$proj_weight" -eq 1 ] && ! git -C "$path" rev-parse --is-inside-work-tree &>/dev/null; then
        score_codex=$((score_codex + 10))
        tool_signals="${tool_signals}\n        no git repo → codex (+10)"
    fi

    # Ralph: progress.md recently modified (within 24h)
    if [ "$proj_weight" -eq 1 ]; then
        local progress_file="${path}/progress.md"
        if [ -f "$progress_file" ]; then
            local prog_mtime
            prog_mtime=$(stat -c %Y "$progress_file" 2>/dev/null || echo "0")
            local now_epoch
            now_epoch=$(date +%s)
            if [ $((now_epoch - prog_mtime)) -lt 86400 ]; then
                score_ralph=$((score_ralph + 10))
                tool_signals="${tool_signals}\n        progress.md recently modified → ralph (+10)"
            fi
        fi
    fi

    # ── Phase 2: Task description scoring ──
    if [ -n "$task_desc" ]; then
        # Claude patterns
        if echo "$task_desc" | grep -qiP 'debug.*complex|multi.?file|full.*stack|deep.*dive'; then
            score_claude=$((score_claude + 30))
            tool_signals="${tool_signals}\n        task: claude high pattern → claude (+30)"
        fi
        if echo "$task_desc" | grep -qiP 'explain.*codebase|trace.*through|understand.*how'; then
            score_claude=$((score_claude + 15))
            tool_signals="${tool_signals}\n        task: claude medium pattern → claude (+15)"
        fi
        if echo "$task_desc" | grep -qiP '\bwhy\b|\breason\b|\bthink\b'; then
            score_claude=$((score_claude + 5))
            tool_signals="${tool_signals}\n        task: claude low pattern → claude (+5)"
        fi

        # Cline patterns
        if echo "$task_desc" | grep -qiP '\bvisual\b|ui.*edit|css.*change|component.*style'; then
            score_cline=$((score_cline + 30))
            tool_signals="${tool_signals}\n        task: cline high pattern → cline (+30)"
        fi
        if echo "$task_desc" | grep -qiP '\bvscode\b|diff.*view|side.?by.?side'; then
            score_cline=$((score_cline + 15))
            tool_signals="${tool_signals}\n        task: cline medium pattern → cline (+15)"
        fi
        if echo "$task_desc" | grep -qiP '\bstyle\b|\blayout\b|\btheme\b'; then
            score_cline=$((score_cline + 5))
            tool_signals="${tool_signals}\n        task: cline low pattern → cline (+5)"
        fi

        # Codex patterns
        if echo "$task_desc" | grep -qiP '\bscript\b|one.?shot|generate.*and.*run|cli.*tool'; then
            score_codex=$((score_codex + 30))
            tool_signals="${tool_signals}\n        task: codex high pattern → codex (+30)"
        fi
        if echo "$task_desc" | grep -qiP '\bbash\b|\bshell\b|\bcommand\b|\bpipe\b'; then
            score_codex=$((score_codex + 15))
            tool_signals="${tool_signals}\n        task: codex medium pattern → codex (+15)"
        fi
        if echo "$task_desc" | grep -qiP '\brun\b|\bexecute\b'; then
            score_codex=$((score_codex + 5))
            tool_signals="${tool_signals}\n        task: codex low pattern → codex (+5)"
        fi

        # Ralph patterns
        if echo "$task_desc" | grep -qiP 'track.*progress|\bprd\b|task.*list|\bmilestone\b'; then
            score_ralph=$((score_ralph + 30))
            tool_signals="${tool_signals}\n        task: ralph high pattern → ralph (+30)"
        fi
        if echo "$task_desc" | grep -qiP 'plan.*sprint|status.*update|\broadmap\b'; then
            score_ralph=$((score_ralph + 15))
            tool_signals="${tool_signals}\n        task: ralph medium pattern → ralph (+15)"
        fi
        if echo "$task_desc" | grep -qiP '\bprogress\b|\bbacklog\b'; then
            score_ralph=$((score_ralph + 5))
            tool_signals="${tool_signals}\n        task: ralph low pattern → ralph (+5)"
        fi

        # KiloCode role task description boosters (same keywords from plugin.ts)
        if echo "$task_desc" | grep -qiP '\barchitect|\bdesign\s+system|\brfc\b|\btrade.?off|\bmulti.?agent'; then
            score_kilo_arch=$((score_kilo_arch + 25))
            tool_signals="${tool_signals}\n        task: arch keywords → kilo-arch (+25)"
        fi
        if echo "$task_desc" | grep -qiP '\bimplement\b|\bbuild\b|\bcreate\s+.*function|\badd\s+.*feature|\bwrite\s+.*code'; then
            score_kilo_code=$((score_kilo_code + 25))
            tool_signals="${tool_signals}\n        task: code keywords → kilo-code (+25)"
        fi
        if echo "$task_desc" | grep -qiP '\bfix\s+.*typo|\brename\b|\bhotfix\b|\bpatch\b'; then
            score_kilo_quick=$((score_kilo_quick + 25))
            tool_signals="${tool_signals}\n        task: quick keywords → kilo-quick (+25)"
        fi
        if echo "$task_desc" | grep -qiP '\breview\s+.*code|\baudit\b|\bfind\s+.*bug|\bsecurity\s+.*check'; then
            score_kilo_review=$((score_kilo_review + 25))
            tool_signals="${tool_signals}\n        task: review keywords → kilo-review (+25)"
        fi
    fi

    # ── Determine winner across all tools ──
    # Build associative-style scoring (bash 4+ arrays)
    local -A all_scores
    all_scores[claude]=$score_claude
    all_scores[kilo-arch]=$score_kilo_arch
    all_scores[kilo-code]=$score_kilo_code
    all_scores[kilo-quick]=$score_kilo_quick
    all_scores[kilo-review]=$score_kilo_review
    all_scores[cline]=$score_cline
    all_scores[codex]=$score_codex
    all_scores[ralph]=$score_ralph

    local best_tool="kilo-code"
    local best_score=${all_scores[kilo-code]}

    for tool_name in claude kilo-arch kilo-code kilo-quick kilo-review cline codex ralph; do
        if [ "${all_scores[$tool_name]}" -gt "$best_score" ]; then
            best_tool="$tool_name"
            best_score="${all_scores[$tool_name]}"
        fi
    done

    # Second-best score
    local second_best=0
    for tool_name in claude kilo-arch kilo-code kilo-quick kilo-review cline codex ralph; do
        if [ "$tool_name" != "$best_tool" ] && [ "${all_scores[$tool_name]}" -gt "$second_best" ]; then
            second_best="${all_scores[$tool_name]}"
        fi
    done
    local margin=$((best_score - second_best))

    # ── Apply margin thresholds ──
    # When user provided a task description, use halved thresholds —
    # explicit user intent is a stronger signal than project heuristics.
    local eff_claude_margin=$claude_upgrade_margin
    local eff_cross_margin=$cross_tool_margin
    if [ -n "$task_desc" ]; then
        eff_claude_margin=$((claude_upgrade_margin / 2))
        eff_cross_margin=$((cross_tool_margin / 2))
    fi

    # Claude needs the highest bar
    if [ "$best_tool" = "claude" ] && [ "$margin" -lt "$eff_claude_margin" ]; then
        best_tool="kilo-code"
        best_score=${all_scores[kilo-code]}
        tool_signals="${tool_signals}\n        margin: claude score below threshold (${margin}<${eff_claude_margin}) → fallback kilo-code"
    fi

    # Cross-tool switches (non-kilo tools) need minimum margin
    case "$best_tool" in
        cline|codex|ralph)
            if [ "$margin" -lt "$eff_cross_margin" ]; then
                tool_signals="${tool_signals}\n        margin: ${best_tool} below cross-tool threshold (${margin}<${eff_cross_margin}) → fallback kilo-code"
                best_tool="kilo-code"
                best_score=${all_scores[kilo-code]}
            fi
            ;;
    esac

    # Recalculate margin after possible fallback
    second_best=0
    for tool_name in claude kilo-arch kilo-code kilo-quick kilo-review cline codex ralph; do
        if [ "$tool_name" != "$best_tool" ] && [ "${all_scores[$tool_name]}" -gt "$second_best" ]; then
            second_best="${all_scores[$tool_name]}"
        fi
    done
    margin=$((best_score - second_best))

    # Confidence level
    local confidence="guess"
    if [ $margin -ge 20 ]; then confidence="high"
    elif [ $margin -ge 10 ]; then confidence="medium"
    elif [ $margin -ge 5 ]; then confidence="low"
    fi

    # Output signals to stderr
    local show_signals
    show_signals=$(config_get "auto_detect" "show_signals")
    if [ "$show_signals" != "false" ]; then
        echo -e "${BLUE}[aiw]${NC} Auto-detecting tool for ${BOLD}${project}${NC}..." >&2
        if [ -n "$task_desc" ]; then
            echo -e "${BLUE}[aiw]${NC} Task: \"${task_desc}\"" >&2
        fi
        echo -e "${BLUE}[aiw]${NC} Tool signals:${tool_signals}" >&2
        echo -e "${BLUE}[aiw]${NC} Scores: claude=${score_claude}  kilo-arch=${score_kilo_arch}  kilo-code=${score_kilo_code}  kilo-quick=${score_kilo_quick}  kilo-review=${score_kilo_review}  cline=${score_cline}  codex=${score_codex}  ralph=${score_ralph}" >&2
        echo -e "${BLUE}[aiw]${NC} → ${GREEN}${best_tool}${NC} (confidence: ${confidence}, margin: ${margin})" >&2
    fi

    echo "$best_tool"
}

# ── Commands ──

cmd_sync() {
    local project="${1:-}"

    info "Syncing workspace..."

    # Fix line endings first (WSL/Windows compatibility)
    find "$WORKSPACE" -type f \( -name "*.sh" -o -name "*.toml" -o -name "*.md" \) -exec sed -i 's/\r$//' {} + 2>/dev/null || true

    local adapters=("claude" "codex" "kilocode" "cline")

    for adapter in "${adapters[@]}"; do
        local script="${ADAPTERS}/${adapter}/generate.sh"
        if [ -f "$script" ]; then
            if [ -n "$project" ]; then
                bash "$script" "$project" 2>/dev/null && ok "${adapter}: ${project}" || warn "${adapter}: ${project} skipped"
            else
                bash "$script" 2>/dev/null && ok "${adapter}: all projects" || warn "${adapter}: some projects skipped"
            fi
        fi
    done

    # Sync Ralph if project specified
    if [ -n "$project" ]; then
        local ralph_script="${ADAPTERS}/ralph/sync-progress.sh"
        if [ -f "$ralph_script" ]; then
            bash "$ralph_script" "$project" --push 2>/dev/null && ok "ralph: ${project}" || true
        fi
    fi

    # Regenerate skill catalog
    local catalog_script="${WORKSPACE}/skills/generate-catalog.py"
    if [ -f "$catalog_script" ]; then
        python3 "$catalog_script" 2>/dev/null && ok "skill catalog regenerated" || warn "skill catalog generation failed"
    fi

    ok "Sync complete."
}

cmd_status() {
    echo -e "${BOLD}${CYAN}Unified AI Workspace v${VERSION}${NC}"
    echo ""

    # Current session
    local session_file="${SESSIONS}/current.json"
    if [ -f "$session_file" ]; then
        echo -e "${BOLD}Active Session:${NC}"
        python3 -c "
import json
with open('${session_file}') as f:
    s = json.load(f)
print(f'  Tool:    {s.get(\"tool\", \"none\")}')
print(f'  Project: {s.get(\"project\", \"none\")}')
print(f'  Started: {s.get(\"started\", \"unknown\")}')
print(f'  Status:  {s.get(\"status\", \"unknown\")}')
" 2>/dev/null || echo "  No active session"
    else
        echo -e "${DIM}No active session.${NC}"
    fi
    echo ""

    # Brief summary
    local brief="${WORKSPACE}/context/brief.md"
    if [ -f "$brief" ]; then
        echo -e "${BOLD}Current Brief:${NC}"
        # Show first content paragraph (skip headers and blank lines)
        sed -n '/^## Current Focus/,/^## /p' "$brief" | head -5 | grep -v '^##' | grep -v '^$' | sed 's/^/  /'
        echo ""
    fi

    # Stuck points
    local stuck="${WORKSPACE}/context/stuck.md"
    if [ -f "$stuck" ] && ! grep -q "^_No active blockers" "$stuck"; then
        echo -e "${BOLD}${RED}Blockers:${NC}"
        grep "^## STUCK-" "$stuck" | sed 's/^/  /' || echo "  None"
        echo ""
    fi

    # Projects
    echo -e "${BOLD}Projects:${NC}"
    for proj in $(list_projects); do
        local path
        path=$(project_path "$proj")
        local marker=""
        if [ "$(default_project)" = "$proj" ]; then
            marker=" ${GREEN}(default)${NC}"
        fi
        echo -e "  ${proj}${marker} — ${path}"
    done
    echo ""

    # Tools
    echo -e "${BOLD}Tools:${NC}"
    echo "  claude, kilocode, cline, codex, ralph"
    echo ""

    # Auto-Routing summary
    local routing_log="${WORKSPACE}/history/routing-decisions.jsonl"
    if [ -f "$routing_log" ] && [ -s "$routing_log" ]; then
        echo -e "${BOLD}Auto-Routing:${NC}"
        python3 -c "
import json
entries = []
with open('${routing_log}') as f:
    for line in f:
        line = line.strip()
        if line:
            try:
                entries.append(json.loads(line))
            except json.JSONDecodeError:
                pass
total = len(entries)
switches = sum(1 for e in entries if e.get('action') == 'switch')
print(f'  {total} decisions, {switches} switches ({switches*100//total}% rate)' if total else '  No decisions yet')
for e in entries[-3:]:
    a = e.get('action', '?')
    icon = '→' if a == 'switch' else '·'
    ts = e.get('ts', '?')[11:19]
    cur = e.get('current', '?')
    tgt = e.get('target', '?')
    m = e.get('margin', 0)
    preview = e.get('prompt_preview', '')[:50]
    if a == 'switch':
        print(f'  {icon} {ts} {cur}→{tgt} (margin={m}) {preview}')
    else:
        print(f'  {icon} {ts} {cur} stay  (margin={m}) {preview}')
print(f'  Run \"aiw routing\" for full log.')
" 2>/dev/null
        echo ""
    fi

    # Skills count
    local catalog="${WORKSPACE}/skills/catalog.json"
    if [ -f "$catalog" ]; then
        local count
        count=$(python3 -c "import json; print(len(json.load(open('${catalog}'))))" 2>/dev/null || echo "?")
        echo -e "${BOLD}Skills:${NC} ${count} in catalog"
    fi
}

cmd_start() {
    local tool="${1:-$(default_tool)}"
    local project="${2:-$(default_project)}"

    # Handle auto-detection: detect best tool + role, then recurse
    if [ "$tool" = "auto" ]; then
        local task_desc=""
        local interactive
        interactive=$(config_get "auto_detect.tool_routing" "interactive_prompt")
        if [ "$interactive" != "false" ]; then
            echo ""
            echo -e "${CYAN}What are you working on?${NC} (or press Enter to auto-detect from project signals)"
            read -r task_desc
        fi

        local detected_tool
        detected_tool=$(auto_detect_tool "$project" "$task_desc")
        echo ""
        cmd_start "${detected_tool}" "$project"
        return $?
    fi

    info "Starting ${tool} on ${project}..."

    # Check for stale session (crash recovery)
    local session_file="${SESSIONS}/current.json"
    if [ -f "$session_file" ]; then
        local stale_tool stale_project stale_started
        stale_tool=$(python3 -c "import json; print(json.load(open('${session_file}'))['tool'])" 2>/dev/null || echo "unknown")
        stale_project=$(python3 -c "import json; print(json.load(open('${session_file}'))['project'])" 2>/dev/null || echo "unknown")
        stale_started=$(python3 -c "import json; print(json.load(open('${session_file}')).get('started','?')[:19])" 2>/dev/null || echo "?")
        warn "Found stale session: ${stale_tool} on ${stale_project} (started ${stale_started})"
        warn "Previous session likely ended uncleanly (crash/hangup/power off)."
        info "Archiving stale session and starting fresh..."
        bash "${ADAPTERS}/_shared/session-logger.sh" --end 2>/dev/null || rm -f "$session_file"
    fi

    # Sync context first
    cmd_sync "$project" 2>/dev/null

    # Record session
    bash "${ADAPTERS}/_shared/session-logger.sh" --start "$tool" "$project"

    # Resolve project path
    local path
    path=$(project_path "$project")

    if [ -z "$path" ] || [ ! -d "$path" ]; then
        err "Project path not found for ${project}"
        return 1
    fi

    # Set up trap to clean up session on ANY exit (crash, Ctrl+C, hangup, kill)
    cleanup_session() {
        bash "${ADAPTERS}/_shared/session-logger.sh" --end 2>/dev/null || true
    }
    trap cleanup_session EXIT INT TERM HUP

    # Launch tool
    case "$tool" in
        claude)
            ok "Launching Claude Code in ${path}"
            ok "Chat history auto-saved to: ~/.claude/projects/"
            echo -e "${DIM}cd ${path} && claude${NC}"
            cd "$path" && claude
            ;;
        kilocode|kilo-arch|kilo-code|kilo-quick|kilo-review)
            local model="" variant="" variant_flag=""
            case "$tool" in
                kilo-arch)
                    model="--model $(config_get_model 'arch')"
                    variant=$(config_get_variant 'arch')
                    ;;
                kilo-code)
                    model="--model $(config_get_model 'code')"
                    variant=$(config_get_variant 'code')
                    ;;
                kilo-quick)
                    model="--model $(config_get_model 'quick')"
                    variant=$(config_get_variant 'quick')
                    ;;
                kilo-review)
                    model="--model $(config_get_model 'review')"
                    variant=$(config_get_variant 'review')
                    ;;
                kilocode)    model="" ;;  # Use default
            esac
            # Build variant flag (only used if non-empty)
            if [ -n "$variant" ]; then
                variant_flag="--variant ${variant}"
            fi
            ok "Launching KiloCode (${tool}) in ${path}"
            [ -n "$variant" ] && ok "Variant: ${variant} (reasoning effort)"
            ok "Chat history auto-saved to: ~/.local/state/kilo/"
            echo -e "${DIM}cd ${path} && kilocode ${model} ${variant_flag}${NC}"
            cd "$path" && kilocode $model $variant_flag
            ;;
        cline)
            ok "Launching Cline in ${path}"
            echo -e "${DIM}Open VS Code in ${path} — Cline reads .clinerules automatically${NC}"
            code "$path"
            ;;
        codex)
            ok "Launching Codex in ${path}"
            ok "Chat history auto-saved to: ~/.codex/"
            echo -e "${DIM}cd ${path} && codex${NC}"
            cd "$path" && codex
            ;;
        ralph)
            ok "Launching Ralph TUI in ${path}"
            echo -e "${DIM}cd ${path} && ralph${NC}"
            cd "$path" && ralph
            ;;
        *)
            err "Unknown tool: ${tool}"
            err "Available: auto, claude, kilocode, kilo-arch, kilo-code, kilo-quick, kilo-review, cline, codex, ralph"
            trap - EXIT INT TERM HUP  # Remove trap before erroring
            return 1
            ;;
    esac

    # Trap handles cleanup — but also do explicit end in case trap doesn't fire
    trap - EXIT INT TERM HUP
    bash "${ADAPTERS}/_shared/session-logger.sh" --end 2>/dev/null || true
}

cmd_switch() {
    local new_tool="${1:?Usage: aiw switch <tool>}"

    local session_file="${SESSIONS}/current.json"
    if [ ! -f "$session_file" ]; then
        warn "No active session. Use 'aiw start <tool> [project]' instead."
        return 1
    fi

    # Read current session
    local current_tool current_project
    current_tool=$(python3 -c "import json; print(json.load(open('${session_file}'))['tool'])" 2>/dev/null)
    current_project=$(python3 -c "import json; print(json.load(open('${session_file}'))['project'])" 2>/dev/null)

    info "Switching from ${current_tool} to ${new_tool} on ${current_project}..."

    # Generate handoff context
    local handoff="${SESSIONS}/handoff-template.md"
    local handoff_file="${SESSIONS}/handoff-$(date +%Y%m%d-%H%M%S).md"
    if [ -f "$handoff" ]; then
        sed "s/{{FROM_TOOL}}/${current_tool}/g; s/{{TO_TOOL}}/${new_tool}/g; s/{{PROJECT}}/${current_project}/g; s/{{TIMESTAMP}}/$(date -Iseconds)/g" "$handoff" > "$handoff_file"
        ok "Handoff context: ${handoff_file}"
    fi

    # End old session, start new one
    bash "${ADAPTERS}/_shared/session-logger.sh" --end 2>/dev/null || true

    # Launch new tool
    cmd_start "$new_tool" "$current_project"
}

cmd_resume() {
    local tool="${1:-$(default_tool)}"

    local session_file="${SESSIONS}/current.json"

    # Try to find last session — either active or most recent archived
    local project=""
    local last_tool=""
    local last_started=""

    if [ -f "$session_file" ]; then
        project=$(python3 -c "import json; print(json.load(open('${session_file}'))['project'])" 2>/dev/null)
        last_tool=$(python3 -c "import json; print(json.load(open('${session_file}'))['tool'])" 2>/dev/null)
        last_started=$(python3 -c "import json; print(json.load(open('${session_file}')).get('started','?')[:19])" 2>/dev/null)
    else
        # Find most recent archived session
        local latest_archive
        latest_archive=$(find "${WORKSPACE}/history/sessions" -name "*.json" -type f 2>/dev/null | sort | tail -1)
        if [ -n "$latest_archive" ]; then
            project=$(python3 -c "import json; print(json.load(open('${latest_archive}'))['project'])" 2>/dev/null)
            last_tool=$(python3 -c "import json; print(json.load(open('${latest_archive}'))['tool'])" 2>/dev/null)
            last_started=$(python3 -c "import json; print(json.load(open('${latest_archive}')).get('started','?')[:19])" 2>/dev/null)
        fi
    fi

    if [ -z "$project" ]; then
        warn "No previous session found. Starting fresh with defaults."
        cmd_start "$tool"
        return
    fi

    echo -e "${BOLD}${CYAN}Resume Context${NC}"
    echo ""
    echo -e "  Last session: ${BOLD}${last_tool}${NC} on ${BOLD}${project}${NC} (${last_started})"
    echo ""

    # Show current brief
    local proj_brief="${WORKSPACE}/context/projects/${project}/brief.md"
    if [ -f "$proj_brief" ]; then
        echo -e "${BOLD}Project Brief:${NC}"
        sed -n '/^## Current/,/^## [^C]/p' "$proj_brief" | head -8 | sed 's/^/  /'
        echo ""
    fi

    # Show stuck points
    local stuck="${WORKSPACE}/context/stuck.md"
    if [ -f "$stuck" ] && ! grep -q "^_No active blockers" "$stuck"; then
        echo -e "${BOLD}${RED}Active Blockers:${NC}"
        grep "^## STUCK-" "$stuck" | sed 's/^/  /' || true
        echo ""
    fi

    # Show last few lines from tool history (what was being discussed)
    echo -e "${BOLD}Recent Tool History:${NC}"
    case "$tool" in
        claude)
            local claude_hist="${WORKSPACE}/history/sources/claude.jsonl"
            if [ -f "$claude_hist" ]; then
                tail -3 "$claude_hist" 2>/dev/null | python3 -c "
import sys, json
for line in sys.stdin:
    try:
        d = json.loads(line.strip())
        msg = d.get('message','')[:100] or d.get('query','')[:100] or str(d)[:100]
        print(f'  {msg}')
    except: pass
" 2>/dev/null || echo "  (could not read history)"
            fi
            ;;
        kilocode|kilo-*)
            local kilo_hist="${WORKSPACE}/history/sources/kilo.jsonl"
            if [ -f "$kilo_hist" ]; then
                tail -3 "$kilo_hist" 2>/dev/null | python3 -c "
import sys, json
for line in sys.stdin:
    try:
        d = json.loads(line.strip())
        msg = d.get('message','')[:100] or d.get('prompt','')[:100] or str(d)[:100]
        print(f'  {msg}')
    except: pass
" 2>/dev/null || echo "  (could not read history)"
            fi
            ;;
        *)
            echo "  (no history reader for ${tool})"
            ;;
    esac
    echo ""

    # Recent routing decisions (if any)
    local routing_log="${WORKSPACE}/history/routing-decisions.jsonl"
    if [ -f "$routing_log" ] && [ -s "$routing_log" ]; then
        echo -e "${BOLD}Recent Auto-Routing:${NC}"
        python3 -c "
import json
entries = []
with open('${routing_log}') as f:
    for line in f:
        line = line.strip()
        if line:
            try:
                entries.append(json.loads(line))
            except json.JSONDecodeError:
                pass
for e in entries[-3:]:
    a = e.get('action', '?')
    icon = '→' if a == 'switch' else '·'
    ts = e.get('ts', '?')[:19]
    cur = e.get('current', '?')
    tgt = e.get('target', '?')
    m = e.get('margin', 0)
    c = e.get('confidence', '?')
    preview = e.get('prompt_preview', '')[:50]
    if a == 'switch':
        print(f'  {icon} [{ts}] {cur}→{tgt} (margin={m}, {c}) {preview}')
    else:
        print(f'  {icon} [{ts}] {cur} stay (margin={m}, {c}) {preview}')
# Suggest optimal tool based on last routing decision
if entries:
    last = entries[-1]
    if last.get('action') == 'switch':
        print(f'  Tip: Last prompt was routed to kilo-{last[\"target\"]}. Consider resuming with that role.')
" 2>/dev/null
        echo ""
    fi

    echo -e "${DIM}Paste this into the tool to resume:${NC}"
    echo ""
    echo "  I'm resuming work on ${project}. Read CLAUDE.md for full context."
    echo "  Check the project brief for current goals. Pick up where we left off."
    echo ""

    info "Launching ${tool} on ${project}..."
    cmd_start "$tool" "$project"
}

cmd_brief() {
    local project="${1:-}"
    local editor="${EDITOR:-${VISUAL:-vi}}"

    if [ -n "$project" ]; then
        local brief="${WORKSPACE}/context/projects/${project}/brief.md"
        if [ -f "$brief" ]; then
            "$editor" "$brief"
        else
            err "No brief.md for project: ${project}"
            return 1
        fi
    else
        "$editor" "${WORKSPACE}/context/brief.md"
    fi

    info "Brief updated. Run 'aiw sync' to propagate."
}

cmd_stuck() {
    local editor="${EDITOR:-${VISUAL:-vi}}"
    "$editor" "${WORKSPACE}/context/stuck.md"
    info "Stuck points updated. Run 'aiw sync' to propagate."
}

cmd_skill() {
    local subcmd="${1:-list}"
    shift 2>/dev/null || true

    case "$subcmd" in
        list)
            local tag_filter="${1:-}"
            local catalog="${WORKSPACE}/skills/catalog.json"
            if [ ! -f "$catalog" ]; then
                err "No catalog found. Run 'aiw sync' first."
                return 1
            fi

            if [ -n "$tag_filter" ]; then
                # Strip --tag= prefix if present
                tag_filter="${tag_filter#--tag=}"
                python3 -c "
import json, sys
tag = '${tag_filter}'
data = json.load(open('${catalog}'))
matches = [s for s in data if tag in s.get('tags', [])]
print(f'Skills matching tag \"{tag}\": {len(matches)}')
print()
for s in matches:
    print(f'  {s[\"name\"]:40s}  [{s[\"source\"]}]  {s[\"description\"][:60]}')
"
            else
                python3 -c "
import json
from collections import Counter
data = json.load(open('${catalog}'))
print(f'Total skills: {len(data)}')
print()
sources = Counter(s['source'] for s in data)
for src, count in sources.most_common():
    print(f'  {src:20s}  {count} skills')
print()
tags = Counter(t for s in data for t in s.get('tags', []))
print('Top tags:')
for tag, count in tags.most_common(15):
    print(f'  {tag:20s}  {count}')
"
            fi
            ;;
        add)
            local path="${1:?Usage: aiw skill add <path>}"
            if [ ! -f "$path" ]; then
                err "File not found: ${path}"
                return 1
            fi
            info "Adding skill: ${path}"
            info "Regenerating catalog..."
            python3 "${WORKSPACE}/skills/generate-catalog.py"
            ok "Skill catalog updated."
            ;;
        search)
            local query="${1:?Usage: aiw skill search <query>}"
            local catalog="${WORKSPACE}/skills/catalog.json"
            python3 -c "
import json, sys
import re
query = '${query}'.lower()
# Normalize hyphens/underscores to spaces for flexible matching
query_norm = re.sub(r'[-_]', ' ', query)
data = json.load(open('${catalog}'))
matches = [s for s in data if query_norm in re.sub(r'[-_]', ' ', s['name'].lower()) or query in s.get('description','').lower()]
print(f'Found {len(matches)} skills matching \"{query}\":')
print()
for s in matches[:20]:
    tags = ', '.join(s.get('tags', []))
    print(f'  {s[\"name\"]:40s}  [{tags}]')
    print(f'    {s[\"description\"][:80]}')
    print()
"
            ;;
        update)
            local dry_run=false
            local source_filter=""
            while [ $# -gt 0 ]; do
                case "$1" in
                    --dry-run) dry_run=true ;;
                    --source=*) source_filter="${1#--source=}" ;;
                esac
                shift
            done

            local plugin_dir
            plugin_dir=$(config_get "skills.sources.plugins" "path")
            local plugin_repo
            plugin_repo=$(dirname "$plugin_dir")  # git root is parent of .claude-plugin
            local state_file="${WORKSPACE}/skills/update-state.json"

            # If source filter set, only allow "plugins" (the only git-based source)
            if [ -n "$source_filter" ] && [ "$source_filter" != "plugins" ]; then
                err "Only 'plugins' source supports update (it's the git-backed source)."
                echo "Other sources (ralph, project-skills) are local directories."
                return 1
            fi

            if [ ! -d "$plugin_repo/.git" ]; then
                err "Git repo not found at ${plugin_repo}"
                return 1
            fi

            info "Checking skill repo: ${plugin_repo}"

            # Fetch latest — try HTTPS first, then SSH fallback
            local fetch_ok=false
            info "Fetching latest from origin..."
            if git -C "$plugin_repo" fetch origin 2>/dev/null; then
                fetch_ok=true
            else
                # HTTPS fetch failed — try switching to SSH
                local current_remote
                current_remote=$(git -C "$plugin_repo" remote get-url origin 2>/dev/null)
                if [[ "$current_remote" == https://github.com/* ]]; then
                    local repo_path
                    repo_path=$(echo "$current_remote" | sed 's|https://github.com/||' | sed 's|\.git$||')
                    local ssh_remote="git@github.com:${repo_path}.git"
                    info "HTTPS fetch failed, trying SSH..."
                    if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=accept-new -T git@github.com 2>&1 | grep -qi "successfully authenticated"; then
                        info "SSH auth works. Switching remote to: ${ssh_remote}"
                        git -C "$plugin_repo" remote set-url origin "$ssh_remote"
                        if git -C "$plugin_repo" fetch origin 2>/dev/null; then
                            fetch_ok=true
                        fi
                    fi
                fi
            fi

            if ! $fetch_ok; then
                warn "Could not fetch from remote (no network or auth)."
                warn "Comparing against last-known origin/main instead."
                if ! git -C "$plugin_repo" rev-parse origin/main >/dev/null 2>&1; then
                    err "No cached origin/main ref. Cannot compare."
                    err "Fix: configure git credentials or SSH key for GitHub."
                    return 1
                fi
            fi

            # Compare HEAD vs origin/main
            local local_head remote_head
            local_head=$(git -C "$plugin_repo" rev-parse HEAD 2>/dev/null)
            remote_head=$(git -C "$plugin_repo" rev-parse origin/main 2>/dev/null)

            if [ "$local_head" = "$remote_head" ]; then
                ok "Already up to date (${local_head:0:7})"
                return 0
            fi

            # Show incoming changes
            echo ""
            echo -e "${BOLD}Incoming changes:${NC}"
            git -C "$plugin_repo" log --oneline "${local_head}..${remote_head}" 2>/dev/null
            echo ""
            echo -e "${BOLD}Files changed:${NC}"
            git -C "$plugin_repo" diff --stat "${local_head}..${remote_head}" 2>/dev/null
            echo ""

            if $dry_run; then
                info "Dry run — no changes applied."
                echo "Run 'aiw skill update' (without --dry-run) to apply."
                return 0
            fi

            if ! $fetch_ok; then
                err "Cannot pull without a successful fetch. Fix network/auth and retry."
                return 1
            fi

            # Stash local changes if any
            local stashed=false
            if ! git -C "$plugin_repo" diff --quiet 2>/dev/null; then
                warn "Stashing local changes..."
                git -C "$plugin_repo" stash push -m "aiw-skill-update-$(date +%Y%m%d%H%M%S)" 2>/dev/null
                stashed=true
            fi

            # Pull with fast-forward only
            info "Pulling changes (fast-forward)..."
            if ! git -C "$plugin_repo" pull --ff-only origin main 2>&1; then
                err "Fast-forward pull failed. The local branch may have diverged."
                err "Fix: cd ${plugin_repo} && git pull --rebase origin main"
                if $stashed; then
                    warn "Restoring stashed changes..."
                    git -C "$plugin_repo" stash pop 2>/dev/null || true
                fi
                return 1
            fi

            local new_head
            new_head=$(git -C "$plugin_repo" rev-parse HEAD 2>/dev/null)

            # Show marketplace version diff
            local mp_file="${plugin_dir}/marketplace.json"
            if [ -f "$mp_file" ]; then
                local mp_version
                mp_version=$(python3 -c "import json; print(json.load(open('${mp_file}')).get('metadata',{}).get('version','unknown'))" 2>/dev/null)
                info "Marketplace version: ${mp_version}"
            fi

            # Regenerate catalog
            info "Regenerating skill catalog..."
            python3 "${WORKSPACE}/skills/generate-catalog.py"

            # Count skills from catalog
            local skill_count
            skill_count=$(python3 -c "import json; print(len(json.load(open('${WORKSPACE}/skills/catalog.json'))))" 2>/dev/null || echo "?")

            # Save update state
            python3 -c "
import json
from datetime import datetime, timezone

state_path = '${state_file}'

# Load existing state or start fresh
try:
    state = json.load(open(state_path))
except Exception:
    state = {}

state['plugins'] = {
    'last_updated': datetime.now(timezone.utc).isoformat(),
    'previous_commit': '${local_head}',
    'current_commit': '${new_head}',
    'marketplace_version': '$(python3 -c "import json; print(json.load(open('${mp_file}')).get('metadata',{}).get('version','?'))" 2>/dev/null || echo "?")',
    'skill_count': ${skill_count},
    'update_method': 'git-pull-ff',
}

with open(state_path, 'w') as f:
    json.dump(state, f, indent=2)
"
            if $stashed; then
                info "Restoring stashed changes..."
                git -C "$plugin_repo" stash pop 2>/dev/null || warn "Stash pop had conflicts — check manually."
            fi

            ok "Updated: ${local_head:0:7} → ${new_head:0:7} (${skill_count} skills in catalog)"
            ;;
        status)
            local catalog="${WORKSPACE}/skills/catalog.json"
            local state_file="${WORKSPACE}/skills/update-state.json"

            echo -e "${BOLD}${CYAN}Skill Sources${NC}"
            echo ""

            # Read source paths from config.toml
            local src_plugins src_ralph src_project
            src_plugins=$(config_get "skills.sources.plugins" "path")
            src_ralph=$(config_get "skills.sources.ralph" "path")
            src_project=$(config_get "skills.sources.project-skills" "path")

            python3 -c "
import json, os, subprocess
from pathlib import Path
from datetime import datetime

sources = {
    'plugins': {
        'path': '${src_plugins}',
        'type': 'claude-plugin (git repo)',
        'git': True,
    },
    'ralph': {
        'path': '${src_ralph}',
        'type': 'ralph-skill (local)',
        'git': False,
    },
    'project-skills': {
        'path': '${src_project}',
        'type': 'claude-project (local)',
        'git': False,
    },
}

# Load catalog for counts
catalog = []
try:
    catalog = json.load(open('${catalog}'))
except Exception:
    pass

source_map = {'claude-plugin': 'plugins', 'ralph': 'ralph', 'project': 'project-skills'}
source_counts = {}
for s in catalog:
    key = source_map.get(s.get('source',''), s.get('source',''))
    source_counts[key] = source_counts.get(key, 0) + 1

for name, info in sources.items():
    exists = os.path.isdir(info['path'])
    count = source_counts.get(name, 0)
    status_icon = '\033[0;32m●\033[0m' if exists else '\033[0;31m●\033[0m'
    print(f'  {status_icon} {name:20s}  {count:4d} skills  ({info[\"type\"]})')
    print(f'    Path: {info[\"path\"]}')

    if info['git'] and exists:
        try:
            head = subprocess.check_output(
                ['git', '-C', info['path'], 'log', '--oneline', '-1'],
                stderr=subprocess.DEVNULL, text=True
            ).strip()
            branch = subprocess.check_output(
                ['git', '-C', info['path'], 'rev-parse', '--abbrev-ref', 'HEAD'],
                stderr=subprocess.DEVNULL, text=True
            ).strip()
            remote = subprocess.check_output(
                ['git', '-C', info['path'], 'remote', 'get-url', 'origin'],
                stderr=subprocess.DEVNULL, text=True
            ).strip()
            print(f'    Branch: {branch}  Latest: {head}')
            print(f'    Remote: {remote}')
        except Exception:
            print(f'    Git: (unable to read)')

    # Show marketplace version if available
    if name == 'plugins':
        mp = os.path.join(info['path'], 'marketplace.json')
        if os.path.isfile(mp):
            try:
                data = json.load(open(mp))
                ver = data.get('metadata', {}).get('version', '?')
                plugin_count = len(data.get('plugins', []))
                print(f'    Marketplace: v{ver} ({plugin_count} plugins)')
            except Exception:
                pass
    print()

print(f'  \033[1mCatalog total: {len(catalog)} skills\033[0m')

# Catalog last generated
try:
    mtime = os.path.getmtime('${catalog}')
    dt = datetime.fromtimestamp(mtime)
    print(f'  Last generated: {dt.strftime(\"%Y-%m-%d %H:%M:%S\")}')
except Exception:
    pass
print()

# Last update state
try:
    state = json.load(open('${state_file}'))
    if 'plugins' in state:
        ps = state['plugins']
        print('\033[1mLast Update\033[0m')
        print(f'  Updated:   {ps.get(\"last_updated\", \"never\")[:19]}')
        print(f'  Commit:    {ps.get(\"current_commit\", \"?\")[:7]}')
        print(f'  Previous:  {ps.get(\"previous_commit\", \"?\")[:7]}')
        print(f'  Version:   {ps.get(\"marketplace_version\", \"?\")}')
        print(f'  Method:    {ps.get(\"update_method\", \"?\")}')
        print()
except Exception:
    print('\033[2mNo update history yet. Run: aiw skill update\033[0m')
    print()
"
            echo -e "${BOLD}Marketplace URLs${NC} ${DIM}(browse only — skills are installed locally)${NC}"
            echo "  PDI ADO:     https://pdidev.visualstudio.com/PDI%20World/_git/pdi-claude-skills-market"
            echo "  Anthropic:   https://github.com/anthropics/skills/tree/main/skills"
            echo "  Smithery:    https://smithery.ai/skills"
            echo "  SkillsLLM:   https://skillsllm.com/"
            echo "  SkillsMP:    https://skillsmp.com/"
            echo ""
            echo -e "${BOLD}How Skills Are Loaded${NC}"
            echo "  1. Sources scanned → catalog.json generated      (during 'aiw sync')"
            echo "  2. 'aiw start <tool>' reads catalog + project context"
            echo "  3. Tool adapter injects relevant skills into tool config:"
            echo "     • Claude  → skills embedded in CLAUDE.md"
            echo "     • KiloCode → skills embedded in .kilocode/rules/rules.md"
            echo "     • Cline   → skills embedded in .clinerules"
            echo "  4. During session, tool loads skills as context"
            echo "  5. Skills matching project tags are auto-prioritized"
            ;;
        *)
            err "Unknown skill command: ${subcmd}"
            echo "Usage: aiw skill [list|add|search|update|status] [args]"
            ;;
    esac
}

cmd_history() {
    local tool_filter=""
    local date_filter=""

    while [ $# -gt 0 ]; do
        case "$1" in
            --tool=*) tool_filter="${1#--tool=}" ;;
            --date=*)
                date_filter="${1#--date=}"
                if [ "$date_filter" = "today" ]; then
                    date_filter=$(date +%Y-%m-%d)
                fi
                ;;
        esac
        shift
    done

    local index="${WORKSPACE}/history/index.jsonl"
    if [ ! -f "$index" ]; then
        warn "No history index found. History tracking starts after first 'aiw start'."
        return
    fi

    python3 -c "
import json
tool_filter = '${tool_filter}'
date_filter = '${date_filter}'
entries = []
with open('${index}') as f:
    for line in f:
        line = line.strip()
        if line:
            try:
                entries.append(json.loads(line))
            except json.JSONDecodeError:
                pass

if tool_filter:
    entries = [e for e in entries if e.get('tool') == tool_filter]
if date_filter:
    entries = [e for e in entries if e.get('date', '').startswith(date_filter)]

print(f'History entries: {len(entries)}')
for e in entries[-20:]:
    print(f'  [{e.get(\"timestamp\",\"?\")[:19]}] {e.get(\"tool\",\"?\")} / {e.get(\"project\",\"?\")} — {e.get(\"summary\",\"\")}')
"
}

cmd_cleanup() {
    info "Cleaning up workspace..."

    # Clean old generated output
    local gen_dir="${WORKSPACE}/output/generated"
    if [ -d "$gen_dir" ]; then
        local threshold
        threshold=$(date -d "30 days ago" +%Y-%m-%d 2>/dev/null || date -v-30d +%Y-%m-%d 2>/dev/null || echo "")
        if [ -n "$threshold" ]; then
            local count=0
            for dir in "${gen_dir}"/*/; do
                local dirname
                dirname=$(basename "$dir")
                if [[ "$dirname" < "$threshold" ]]; then
                    rm -rf "$dir"
                    ((count++)) || true
                fi
            done
            ok "Removed ${count} old generated output directories"
        fi
    fi

    # Compact history index (remove duplicates)
    local index="${WORKSPACE}/history/index.jsonl"
    if [ -f "$index" ]; then
        local before
        before=$(wc -l < "$index")
        sort -u "$index" > "${index}.tmp" && mv "${index}.tmp" "$index"
        local after
        after=$(wc -l < "$index")
        ok "History index: ${before} -> ${after} entries (removed $((before - after)) duplicates)"
    fi

    ok "Cleanup complete."
}

cmd_models() {
    local subcmd="${1:-show}"
    shift 2>/dev/null || true

    local discover="${ADAPTERS}/_shared/discover-models.sh"
    local bashrc="${HOME}/.bashrc"
    local marker_start="# >>> aiw-models-start >>>"
    local marker_end="# <<< aiw-models-end <<<"
    local bedrock_prefix="amazon-bedrock/"

    case "$subcmd" in
        show)
            # Display current assignments vs latest available
            echo -e "${BOLD}${CYAN}Model Assignments${NC}"
            echo ""

            # Current from config.toml
            local c_arch c_code c_quick c_review
            c_arch=$(config_get_model 'arch')
            c_code=$(config_get_model 'code')
            c_quick=$(config_get_model 'quick')
            c_review=$(config_get_model 'review')

            # Variants from config.toml
            local v_arch v_code v_quick v_review
            v_arch=$(config_get_variant 'arch')
            v_code=$(config_get_variant 'code')
            v_quick=$(config_get_variant 'quick')
            v_review=$(config_get_variant 'review')

            # Latest from Bedrock
            local latest
            latest=$(bash "$discover" --json 2>/dev/null) || {
                err "Could not query Bedrock. Showing config.toml values only."
                echo ""
                printf "  ${BOLD}%-8s${NC} %-55s %s\n" "arch" "$c_arch" "${v_arch:-(default)}"
                printf "  ${BOLD}%-8s${NC} %-55s %s\n" "code" "$c_code" "${v_code:-(default)}"
                printf "  ${BOLD}%-8s${NC} %-55s %s\n" "quick" "$c_quick" "${v_quick:-(default)}"
                printf "  ${BOLD}%-8s${NC} %-55s %s\n" "review" "$c_review" "${v_review:-(default)}"
                return
            }

            local l_arch l_code l_quick l_review
            l_arch=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['arch'])")
            l_code=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['code'])")
            l_quick=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['quick'])")
            l_review=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['review'])")

            printf "  ${BOLD}%-8s %-55s %-55s %-10s %s${NC}\n" "Role" "Current (config.toml)" "Latest (Bedrock)" "Variant" "Status"
            echo "  $(printf '%0.s─' {1..145})"

            local roles=("arch" "code" "quick" "review")
            local current_vals=("$c_arch" "$c_code" "$c_quick" "$c_review")
            local latest_vals=("$l_arch" "$l_code" "$l_quick" "$l_review")
            local variant_vals=("${v_arch:-(default)}" "${v_code:-(default)}" "${v_quick:-(default)}" "${v_review:-(default)}")

            for i in 0 1 2 3; do
                local role="${roles[$i]}"
                local cur="${current_vals[$i]}"
                local lat="${bedrock_prefix}${latest_vals[$i]}"
                local var="${variant_vals[$i]}"
                local status_icon
                if [ "$cur" = "$lat" ]; then
                    status_icon="${GREEN}✓ up-to-date${NC}"
                else
                    status_icon="${YELLOW}↑ newer available${NC}"
                fi
                printf "  %-8s %-55s %-55s %-10s %b\n" "$role" "$cur" "$lat" "$var" "$status_icon"
            done
            echo ""

            # Show all available profiles
            echo -e "${DIM}All active Bedrock profiles:${NC}"
            bash "$discover" --table 2>/dev/null | tail -n +7
            ;;

        update)
            local dry_run=false
            if [ "${1:-}" = "--dry-run" ]; then
                dry_run=true
                shift
            fi

            info "Discovering latest models from Bedrock..."
            local latest
            latest=$(bash "$discover" --json 2>/dev/null) || {
                err "Could not query Bedrock. Check AWS CLI configuration."
                return 1
            }

            local l_arch l_code l_quick l_review
            l_arch=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['arch'])")
            l_code=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['code'])")
            l_quick=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['quick'])")
            l_review=$(echo "$latest" | python3 -c "import json,sys; print(json.load(sys.stdin)['review'])")

            # Build new config values (with bedrock prefix)
            local new_arch="${bedrock_prefix}${l_arch}"
            local new_code="${bedrock_prefix}${l_code}"
            local new_quick="${bedrock_prefix}${l_quick}"
            local new_review="${bedrock_prefix}${l_review}"

            # Current values
            local c_arch c_code c_quick c_review
            c_arch=$(config_get_model 'arch')
            c_code=$(config_get_model 'code')
            c_quick=$(config_get_model 'quick')
            c_review=$(config_get_model 'review')

            # Show changes
            local has_changes=false
            echo ""
            echo -e "${BOLD}Changes:${NC}"
            for role in arch code quick review; do
                local cur new
                case "$role" in
                    arch)   cur="$c_arch";   new="$new_arch" ;;
                    code)   cur="$c_code";   new="$new_code" ;;
                    quick)  cur="$c_quick";  new="$new_quick" ;;
                    review) cur="$c_review"; new="$new_review" ;;
                esac
                if [ "$cur" != "$new" ]; then
                    echo -e "  ${role}: ${RED}${cur}${NC} → ${GREEN}${new}${NC}"
                    has_changes=true
                else
                    echo -e "  ${role}: ${DIM}${cur} (unchanged)${NC}"
                fi
            done
            echo ""

            if [ "$has_changes" = false ]; then
                ok "All models are already up-to-date."
                return 0
            fi

            if [ "$dry_run" = true ]; then
                warn "Dry run — no files modified."
                return 0
            fi

            # ── Update config.toml ──
            info "Updating config.toml..."
            python3 -c "
import re, sys

config_path = '${CONFIG}'
with open(config_path) as f:
    content = f.read()

# Replace model values in [tools.kilocode.models] section
models = {
    'arch': '${new_arch}',
    'code': '${new_code}',
    'quick': '${new_quick}',
    'review': '${new_review}',
}

# Find the section and replace each key
in_section = False
lines = content.split('\n')
new_lines = []
for line in lines:
    if line.strip() == '[tools.kilocode.models]':
        in_section = True
        new_lines.append(line)
        continue
    if in_section and line.strip().startswith('['):
        in_section = False
    if in_section:
        for key, val in models.items():
            if line.strip().startswith(key + ' '):
                line = f'{key} = \"{val}\"'
                break
    new_lines.append(line)

with open(config_path, 'w') as f:
    f.write('\n'.join(new_lines))
"
            ok "config.toml updated."

            # ── Update .bashrc aliases ──
            # Aliases delegate to aiw start (which reads model+variant from config.toml and syncs)
            info "Updating .bashrc aliases..."

            python3 - "$bashrc" "$marker_start" "$marker_end" << 'BASHRC_PY'
import re, sys

bashrc_path, m_start, m_end = sys.argv[1], sys.argv[2], sys.argv[3]

# Aliases delegate to aiw start — model+variant read from config.toml at runtime
alias_block = "\n".join([
    m_start,
    "alias kilo-arch='aiw start kilo-arch'",
    "alias kilo-code='aiw start kilo-code'",
    "alias kilo-quick='aiw start kilo-quick'",
    "alias kilo-review='aiw start kilo-review'",
    "alias kilo-auto='aiw start auto'",
    m_end,
])

with open(bashrc_path) as f:
    content = f.read()

if m_start in content:
    # Replace between markers (inclusive)
    pattern = re.escape(m_start) + r".*?" + re.escape(m_end)
    content = re.sub(pattern, alias_block, content, flags=re.DOTALL)
else:
    # Find existing kilo- aliases and wrap them
    lines = content.split("\n")
    alias_indices = [i for i, line in enumerate(lines) if line.strip().startswith("alias kilo-")]

    if not alias_indices:
        content = content.rstrip("\n") + "\n\n" + alias_block + "\n"
    else:
        first, last = min(alias_indices), max(alias_indices)
        # Also grab the comment line above if it exists
        if first > 0 and "KiloCode CLI" in lines[first - 1]:
            first -= 1
        lines[first:last + 1] = [alias_block]
        content = "\n".join(lines)

with open(bashrc_path, "w") as f:
    f.write(content)
BASHRC_PY
            ok ".bashrc aliases updated."
            echo -e "${DIM}Run 'source ~/.bashrc' to activate new aliases.${NC}"
            ;;

        set)
            local role="${1:?Usage: aiw models set <role> <model-id>}"
            local model_id="${2:?Usage: aiw models set <role> <model-id>}"

            # Validate role
            case "$role" in
                arch|code|quick|review) ;;
                *) err "Invalid role: ${role}. Must be arch, code, quick, or review."; return 1 ;;
            esac

            info "Setting ${role} = ${model_id}"

            # Update config.toml
            python3 -c "
config_path = '${CONFIG}'
role = '${role}'
model_id = '${model_id}'

with open(config_path) as f:
    content = f.read()

in_section = False
lines = content.split('\n')
new_lines = []
for line in lines:
    if line.strip() == '[tools.kilocode.models]':
        in_section = True
        new_lines.append(line)
        continue
    if in_section and line.strip().startswith('['):
        in_section = False
    if in_section and line.strip().startswith(role + ' '):
        line = f'{role} = \"{model_id}\"'
    new_lines.append(line)

with open(config_path, 'w') as f:
    f.write('\n'.join(new_lines))
"
            ok "config.toml updated: ${role} = ${model_id}"
            ok "Aliases use 'aiw start' — model read from config.toml at runtime."
            ;;

        set-variant)
            local role="${1:?Usage: aiw models set-variant <role> <variant|default>}"
            local new_variant="${2:?Usage: aiw models set-variant <role> <variant|default>}"

            # Validate role
            case "$role" in
                arch|code|quick|review) ;;
                *) err "Invalid role: ${role}. Must be arch, code, quick, or review."; return 1 ;;
            esac

            # Validate variant
            case "$new_variant" in
                high|max|minimal) ;;
                default|"") new_variant="" ;;
                *) err "Invalid variant: ${new_variant}. Must be high, max, minimal, or default."; return 1 ;;
            esac

            info "Setting variant for ${role} = ${new_variant:-(default)}"

            # Update config.toml [tools.kilocode.variants] section
            python3 -c "
config_path = '${CONFIG}'
role = '${role}'
variant = '${new_variant}'

with open(config_path) as f:
    content = f.read()

in_section = False
lines = content.split('\n')
new_lines = []
for line in lines:
    if line.strip() == '[tools.kilocode.variants]':
        in_section = True
        new_lines.append(line)
        continue
    if in_section and line.strip().startswith('['):
        in_section = False
    if in_section and line.strip().startswith(role + ' '):
        line = f'{role} = \"{variant}\"'
    new_lines.append(line)

with open(config_path, 'w') as f:
    f.write('\n'.join(new_lines))
"
            ok "config.toml updated: ${role} variant = ${new_variant:-(default)}"
            ok "Aliases use 'aiw start' — variant read from config.toml at runtime."
            ;;

        reset)
            info "Resetting to auto-detected latest models..."
            cmd_models update "$@"
            ;;

        *)
            err "Unknown models command: ${subcmd}"
            echo "Usage:"
            echo "  aiw models                          Show current models and variants"
            echo "  aiw models update                   Auto-detect latest, update config + aliases"
            echo "  aiw models update --dry-run         Show what would change"
            echo "  aiw models set <role> <id>          Pin a specific model to a role"
            echo "  aiw models set-variant <role> <val> Set reasoning effort (high/max/minimal/default)"
            echo "  aiw models reset                    Reset to auto-detected latest"
            return 1
            ;;
    esac
}

cmd_help() {
    echo -e "${BOLD}${CYAN}aiw${NC} — Unified AI Workspace CLI v${VERSION}"
    echo ""
    echo -e "${BOLD}USAGE:${NC}"
    echo "  aiw <command> [args]"
    echo ""
    echo -e "${BOLD}COMMANDS:${NC}"
    echo "  sync [project]          Regenerate all tool config files from shared context"
    echo "  status                  Show current session, brief, projects, skills"
    echo "  start <tool> [project]  Sync context and launch a tool"
    echo "  start auto [project]    Auto-detect best tool + model and launch"
    echo "  switch <tool>           Handoff current session to another tool"
    echo "  resume [tool]           Resume last session"
    echo "  brief [project]         Open brief.md in \$EDITOR"
    echo "  stuck                   Open stuck.md in \$EDITOR"
    echo "  skill list [--tag=TAG]  List skills from catalog"
    echo "  skill search <query>    Search skills by name/description"
    echo "  skill add <path>        Register skill and regenerate catalog"
    echo "  skill update [--dry-run] [--source=X]  Pull latest skills, regenerate catalog"
    echo "  skill status            Show source health, counts, and skill loading flow"
    echo "  models                          Show current models and variants"
    echo "  models update                   Auto-detect latest models, update config + aliases"
    echo "  models update --dry-run         Show what would change without writing"
    echo "  models set <role> <id>          Pin a specific model to a role"
    echo "  models set-variant <role> <val> Set reasoning effort (high/max/minimal/default)"
    echo "  models reset                    Reset to auto-detected latest"
    echo "  routing                         Show recent auto-routing decisions"
    echo "  routing stats                   Show switch frequency per role"
    echo "  routing clear                   Clear routing log"
    echo "  history [--tool=X] [--date=Y]  Search unified history"
    echo "  cleanup                 Remove old outputs, deduplicate history"
    echo "  version                 Show version"
    echo "  help                    Show this help"
    echo ""
    echo -e "${BOLD}TOOLS:${NC}"
    echo "  auto, claude, kilocode, kilo-arch, kilo-code, kilo-quick, kilo-review,"
    echo "  cline, codex, ralph"
    echo ""
    echo -e "${BOLD}PROJECTS:${NC}"
    for proj in $(list_projects 2>/dev/null); do
        echo "  ${proj}"
    done
    echo ""
    echo -e "${BOLD}EXAMPLES:${NC}"
    echo "  aiw sync                          # Sync all projects, all tools"
    echo "  aiw sync n8n-workflows            # Sync one project"
    echo "  aiw start claude n8n-workflows    # Launch Claude Code with context"
    echo "  aiw start auto n8n-workflows      # Auto-detect best tool + model for project"
    echo "  aiw start kilo-code               # Launch KiloCode Sonnet 4.5"
    echo "  aiw switch kilocode               # Handoff to KiloCode"
    echo "  aiw skill list --tag=n8n          # List n8n skills"
    echo "  aiw brief n8n-workflows           # Edit project brief"
    echo "  aiw history --tool=claude --date=today"
}

cmd_routing() {
    local subcmd="${1:-show}"
    local log_file="${WORKSPACE}/history/routing-decisions.jsonl"

    case "$subcmd" in
        show)
            if [ ! -f "$log_file" ]; then
                warn "No routing decisions logged yet."
                warn "Routing log will appear after the KiloCode auto-routing plugin processes prompts."
                return
            fi

            echo -e "${BOLD}${CYAN}Recent Routing Decisions${NC}"
            echo ""
            python3 -c "
import json, sys

entries = []
with open('${log_file}') as f:
    for line in f:
        line = line.strip()
        if line:
            try:
                entries.append(json.loads(line))
            except json.JSONDecodeError:
                pass

for e in entries[-20:]:
    action = e.get('action', '?')
    icon = '→' if action == 'switch' else '·'
    ts = e.get('ts', '?')[:19]
    current = e.get('current', '?')
    target = e.get('target', '?')
    margin = e.get('margin', 0)
    conf = e.get('confidence', '?')
    preview = e.get('prompt_preview', '')[:60]
    scores = e.get('scores', {})
    score_str = ' '.join(f'{k}={v}' for k, v in scores.items())

    if action == 'switch':
        print(f'  {icon} [{ts}] {current} → {target}  margin={margin} ({conf})  {preview}')
    else:
        print(f'  {icon} [{ts}] {current} (stay)     margin={margin} ({conf})  {preview}')
"
            ;;

        stats)
            if [ ! -f "$log_file" ]; then
                warn "No routing decisions logged yet."
                return
            fi

            echo -e "${BOLD}${CYAN}Routing Statistics${NC}"
            echo ""
            python3 -c "
import json
from collections import Counter

entries = []
with open('${log_file}') as f:
    for line in f:
        line = line.strip()
        if line:
            try:
                entries.append(json.loads(line))
            except json.JSONDecodeError:
                pass

total = len(entries)
switches = [e for e in entries if e.get('action') == 'switch']
stays = [e for e in entries if e.get('action') == 'stay']

print(f'  Total decisions:  {total}')
print(f'  Switches:         {len(switches)}')
print(f'  Stays:            {len(stays)}')
if total > 0:
    print(f'  Switch rate:      {len(switches)*100//total}%')
print()

if switches:
    print('  Switch targets:')
    targets = Counter(e.get('target') for e in switches)
    for role, count in targets.most_common():
        print(f'    {role:8s}  {count}')
    print()

    print('  Switch sources:')
    sources = Counter(e.get('current') for e in switches)
    for role, count in sources.most_common():
        print(f'    {role:8s}  {count}')
    print()

print('  Confidence distribution:')
confs = Counter(e.get('confidence') for e in entries)
for conf, count in confs.most_common():
    print(f'    {conf:8s}  {count}')
"
            ;;

        clear)
            if [ -f "$log_file" ]; then
                rm -f "$log_file"
                ok "Routing log cleared."
            else
                info "No routing log to clear."
            fi
            ;;

        *)
            err "Unknown routing command: ${subcmd}"
            echo "Usage:"
            echo "  aiw routing               Show recent routing decisions (last 20)"
            echo "  aiw routing stats          Show switch frequency per role"
            echo "  aiw routing clear          Clear routing log"
            return 1
            ;;
    esac
}

# ── Main Dispatch ──

check_workspace

case "${1:-help}" in
    sync)       shift; cmd_sync "$@" ;;
    status)     cmd_status ;;
    start)      shift; cmd_start "$@" ;;
    switch)     shift; cmd_switch "$@" ;;
    resume)     shift; cmd_resume "$@" ;;
    brief)      shift; cmd_brief "$@" ;;
    stuck)      cmd_stuck ;;
    skill)      shift; cmd_skill "$@" ;;
    models)     shift; cmd_models "$@" ;;
    routing)    shift; cmd_routing "$@" ;;
    history)    shift; cmd_history "$@" ;;
    cleanup)    cmd_cleanup ;;
    version)    echo "aiw v${VERSION}" ;;
    help|--help|-h) cmd_help ;;
    *)
        err "Unknown command: $1"
        echo "Run 'aiw help' for usage."
        exit 1
        ;;
esac
